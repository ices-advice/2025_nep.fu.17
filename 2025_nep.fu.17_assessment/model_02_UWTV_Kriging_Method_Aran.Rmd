---
title: "FU17_Kriging_2025"
author: "JD/MAE/HJ"
date: "`r format(Sys.Date(), '%d/%m/%Y')`"
output:
  html_document:
        number_sections: yes
        toc: yes
        toc_float: yes
---

21/08/2025. Migration from RGeostats to gstlearn completed by Mikel Aristegui  
gstlearn vignettes:  
https://soft.mines-paristech.fr/gstlearn/courses-latest/r/
<br>
specially helpful for this migration:  
https://soft.mines-paristech.fr/gstlearn/courses-latest/r/04_Variography.html  
https://soft.mines-paristech.fr/gstlearn/courses-latest/r/05_Kriging.html

<br>
**This markdown document contains the full kriging procedure for the Aran (FU17) for year 2025.**

<br>
I am using `r R.Version()[14]`. 
First we load the required packages.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libs, message=FALSE, echo=TRUE, warning=FALSE}
rm(list = ls())
gc()

library(fields)
library(gstlearn)
library(maps)
library(mapproj)
.Last.projection=list(active=F,projection="mean",parameters=NULL,orientation=NULL)
library(RColorBrewer)
library(sf)
library(tidyverse)
library(lwgeom)
library(icesTAF)
library(sessioninfo)

```

# Setup options

```{r setupoptions}
curr.year <- 2025
dat.year <- curr.year -1
fu.n <- "FU17"

save.plots <- F # set it up as T or F whether you want to save the plots when running all the chunks or kniting the document
save.tables <- F # set it up as T or F whether you want to save the tables "propmature"" and the "L50" into .txt files when running all the chunks or knitting the document
```


# Introduction

The goals of this R Markdown document are to:

* Kriging analysis of UWTV survey data using RGeostats package.  
* Write TAF data tables

Files before (inside "model/UWTV"): ###NEED to update files

* europa.txt
* pol.AranIBP.csv
* fu17.tv.final.2025.csv
* ggins.compiled.Aran.contourplot.csv
* AranGrounds.Summary.ADG.2024



Files before (inside "boot/data/shp):

* nep.17.ground.shp


Files after (inside "model_02"):

* fu17.uwtv.summary.statistics.adg.csv
* FU17_Number UWTV Stations.png
* FU17_Abundance_estimates.png
* FU17_meandensity.png
* FU17_uncertainty_estimates
* FU17_violin.plot.density.png
* FU17_violin.plot.counts.png
* FU17_violin.plot.distanceoverground.png
* FU17_contour.plot.png

# Data Work Up
<a href="#top">Back to top</a>

This markdown document contains the full kriging procedure for the Aran ground from `dat.year`.
kriging is carried out using  RGeostats package from MINES ParisTech - Fontainebleau - France.
Download here: http://rgeostats.free.fr/download.php

The final result is the UWTV abundance estimates summary which forms part of the input data for generating catch advice in the Autumn.
Outputs various report figures and tables.

Marine Institute UWTV survey reports are available @ https://oar.marine.ie/handle/10793/1658.

The Working Group on Nephrops Surveys (WGNEPS) is the international coordination group for Nephrops underwater television and trawl surveys within ICES @ https://www.ices.dk/community/groups/Pages/WGNEPS.aspx


## Copy other data from boot/data/ 
```{r copy_data , echo=TRUE, warning=FALSE, fig.height=8, fig.width=8}
cp("boot/data/UWTV/AranGrounds.Summary.ADG.2024.csv", "model/UWTV/AranGrounds.Summary.ADG.2024.csv")

cp("boot/data/UWTV/pol.AranIBP.csv", "model/UWTV/pol.AranIBP.csv")
cp("boot/data/UWTV/europa.txt", "model/UWTV/europa.txt")

cp("boot/data/UWTV/fu17.tv.final.2025.csv", "model/UWTV/fu17.tv.final.2025.csv")

cp("boot/data/UWTV/nep.uwtv.all.data.sql.csv", "model/UWTV/nep.uwtv.all.data.sql.csv")

cp("boot/data/UWTV/ggins.compiled.Aran.contourplot.csv", "model/UWTV/ggins.compiled.Aran.contourplot.csv") 

cp("boot/data/shp", "model")
```

<a href="#top">Back to top</a>


## Load the UWTV survey abundance data and subset for assessment year. 
<a href="#top">Back to top</a>

The data is available only in MI SQL database and it is extracted as a data object.

```{r data, echo=TRUE, message=FALSE, fig.cap="UWTV survey datapoints plot."}


nep.all<-read.csv("model/UWTV/nep.uwtv.all.data.sql.csv")
nep.all<- subset(nep.all,Ground=="Aran")


nep <- subset(nep.all, Year==2025 & Ground=="Aran")
nep <- nep[, c("Year", "Ship_Mid_Longitude", "SHIP_Mid_Latitude", "AdjustedBurrowDensity")]

summ <- nep.all %>% group_by(Year) %>%
  summarise (TotStations = length(StationNumber),
             TotCount = sum(NephropsBurrowCount),
             TotDistance = sum(DistanceOverGround),
             AveDoG = mean(DistanceOverGround),
             AveDens.Adj = mean(AdjustedBurrowDensity))

knitr::kable(summ , digits=3)

```




## Data QC

### Violin  plots Density
<a href="#top">Back to top</a>
May move this to report section

Creates violin plots to visualize the distribution of Nephrops burrow density (Density_Adjusted) across different years.
```{r violin1, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Violin Plot."}

v <- ggplot(nep.all, aes(x=as.factor(Year),y=AdjustedBurrowDensity))+ 
  geom_violin(aes(group=Year,colour=Year,fill=Year),alpha=0.5, 
              kernel="rectangular")+           # passes to stat_density, makes violin rectangular 
  geom_boxplot(aes(group=Year), width=.2)+    
  stat_summary(fun=mean, geom="line", colour="blue", aes(group=1)) +
  xlab("Year")+                                # label one axis
  ylab("Density burrow/m-2")+                       # label the other
  theme_bw()+                                  # make white background on plot
  theme(legend.position = "none")              # suppress legend

v + theme(axis.title.x=element_text(size=10),
          axis.title.y=element_text(size=10))

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_violin_plot_density.png")
}
```

### Violin  plots Counts

May move this to report section

```{r violin2, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Violin Plot."}

v <- ggplot(nep.all, aes(x=as.factor(Year),y=NephropsBurrowCount))+ 
  geom_violin(aes(group=Year,colour=Year,fill=Year),alpha=0.5, 
              kernel="rectangular")+           # passes to stat_density, makes violin rectangular 
  geom_boxplot(aes(group=Year), width=.2)+    
  stat_summary(fun.y=mean, geom="line", colour="blue", aes(group=1)) +
  xlab("Year")+                                # label one axis
  ylab("Verified Burrow Counts")+                       # label the other
  theme_bw()+                                  # make white background on plot
  theme(legend.position = "none")              # suppress legend

v + theme(axis.title.x=element_text(size=10),
          axis.title.y=element_text(size=10))

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_violin_plot_counts.png")
}
```


### Violin  plots DistanceOverGround

May move this to report section

```{r violin3, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Violin Plot."}

v <- ggplot(nep.all, aes(x=as.factor(Year),y=DistanceOverGround))+ 
  geom_violin(aes(group=Year,colour=Year,fill=Year),alpha=0.5, 
              kernel="rectangular")+           # passes to stat_density, makes violin rectangular 
  geom_boxplot(aes(group=Year), width=.2)+    
  stat_summary(fun.y=mean, geom="line", colour="blue", aes(group=1)) +
  xlab("Year")+                                # label one axis
  ylab("Distance Over Ground metres")+                       # label the other
  theme_bw()+                                  # make white background on plot
  theme(legend.position = "none")              # suppress legend

v + theme(axis.title.x=element_text(size=10),
          axis.title.y=element_text(size=10))

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_violin_plot_dog.png")
}

```

### DOG source, FOV multiplier Check.


```{r check, echo=FALSE}

table(nep.all$Year, nep.all$DistanceSource, nep.all$FOVMultiplier)
```
<a href="#top">Back to top</a>


# Kriging


## Create a gstlearn database and plot the data to check.
<a href="#top">Back to top</a>

```{r db, echo=TRUE, message=FALSE, fig.cap="UWTV survey datapoints plot."}

surv.yr <- mean(nep$Year)
mt <- paste(surv.yr, "FU17 UWTV")

# create .csv to be read by gstlearn. No need anymore
# write.csv(nep, paste0("nep", curr.year, ".csv"), row.names = F)

# Create db with gstlearn
data.db = fromTL(nep)
# data.db$display()

# Set Coordinates (x1 and x2) and Variable (z)
data.db$setLocators(c("Ship_Mid_Longitude", "SHIP_Mid_Latitude"), ELoc_X())
data.db$setLocator("AdjustedBurrowDensity", ELoc_Z(), cleanSameLocator=TRUE)
# data.db[] # display as data.frame
# If we want to see detailed info of certain columns:
dbfmt = DbStringFormat_createFromFlags(flag_stats=TRUE, names=c("AdjustedBurrowDensity"))
data.db$display(dbfmt)

# Plotting with gstlearn
plot.init(asp=1.5) +
  plot.symbol(data.db,
              nameSize = "AdjustedBurrowDensity",
              nameColor="AdjustedBurrowDensity",
              flagLegend = TRUE,
              legendNameColor="Adjusted Burrow Density",
              legendNameSize="Adjusted Burrow Density") +
  plot.decoration(title=mt, xlab="Longitude", ylab="Latitude")

```




## FU and Europe polygons
<a href="#top">Back to top</a>

Load FU polygon delimiting the research survey domain and create polygon structure
 
```{r poly, echo=T, message=FALSE, fig.cap=" UWTV survey domain plot."}

# Plotting with gstlearn
# set plot limits
plot_lim_x <- c(-10.5, -9.7)
plot_lim_y <- c(52.75, 53.2)
# FU
# Create db from csv with gstlearn
pol.FU17 = Polygons_createFromCSV(filename="boot/data/UWTV/pol.AranIBP.csv")
pol.FU17$display()

plot.init() +
  plot.polygon(pol.FU17) +
  plot.decoration(title=mt, xlab="Longitude", ylab="Latitude")


# Europe
europa <- read.table("boot/data/UWTV/europa.txt", header=T)
europa<- europa[complete.cases(europa$x, europa$y), ] 
europa <- subset(europa, x > plot_lim_x[1] & x < plot_lim_x[2] & y > plot_lim_y[1] & y < plot_lim_y[2]) # Cropping Europe polygon. I need to do this, if not Europe's polygon breaks when plotting it
europa_pol = Polygons() #new empty polygon object called europa_pol
polyelem1 = PolyElem(x=europa$x, y = europa$y) #polygon element (polyelem1) using the x and y coordinates from your europa dataset.
europa_pol$addPolyElem(polyelem1)#Takes the polygon element (polyelem1) and adds it into the polygon container (europa_pol).

# plot.init() +
#   plot.polygon(europa_pol)


# select points inside polygon

db_polygon(data.db, pol.FU17) # Now we have "Number of active samples" for all the points inside the polygon

plot.init(xlim = plot_lim_x, ylim = plot_lim_y, asp=1.5) +
  plot.symbol(data.db,
                   nameSize = "AdjustedBurrowDensity",
                   nameColor="AdjustedBurrowDensity",
                   flagLegend = T,
                   legendNameColor="Adjusted Burrow Density") +
  plot.decoration(title=paste0(mt, " (all stns)"), xlab="Longitude", ylab="Latitude") +
  plot.polygon(pol.FU17, fill=NA)

```


## Visualizing the data set (in projected space).
<a href="#top">Back to top</a>

In RGeostats we used a projected space based on the mean of the points. From 2025 on, in gstlearn, we will use: - If the area stays within one UTM zone: use that UTM. - If it straddles a UTM boundary: use a local Transverse Mercator centered on the polygon centroid (“local UTM”). Good for kriging areas like our FUs (1.000 km2 - 10.000 km2) Then checking for points inside and outside the polygon.
 
```{r project, echo=TRUE, message=FALSE, fig.cap="Projected space and check datapoints inside survey domain plot"}

source("boot/initial/functions/functions_for_gstlearn.R")

# Project samples points
pts_sf <- st_as_sf(data.frame(
  lon = nep$Ship_Mid_Longitude,
  lat = nep$SHIP_Mid_Latitude,
  value = nep$AdjustedBurrowDensity
), coords = c("lon", "lat"), crs = 4326)
# We'll choose best projection for the polygon
pol.coords <- read.table("boot/data/UWTV/pol.AranIBP.csv",header=T,sep=',') 
coords <- as.matrix(pol.coords)

# Run helper
prep <- prep_for_gstlearn(coords_polygon = coords, pts_sf = pts_sf, value_col = "value")
# Now we have:
prep$polygon_xy   # matrix of [x,y] in meters (for PolyElem)
prep$points_df    # data.frame(x, y, z) for gstlearn
# prep$grid_df      # grid data.frame(x, y) (optional)
prep$crs_used     # which CRS was chosen

# New projected polygon
pol.FU17_m <- Polygons() # in metres
pol.FU17_m$addPolyElem(PolyElem(x = prep$polygon_xy[,1],
                              y = prep$polygon_xy[,2]))
pol.FU17_m$getSurface()/1000000   # area in km2 - 1201.828 km2

# New projected database
db.c1 = fromTL(prep$points_df)
db.c1$display()
# db.c1[] # display as data.frame
# Set Coordinates (x1 and x2) and Variable (z)
db.c1$setLocators(c("x", "y"), ELoc_X())
db.c1$setLocator("AdjustedBurrowDensity", ELoc_Z(), cleanSameLocator=TRUE)
# db.c1$display()

# select points inside polygon
db_polygon(db.c1, pol.FU17_m) # Now we have "Number of active samples" for all the points inside the polygon
db.c1$display()

# Now only "active samples" inside the polygon will be plotted
plot.init() + # Cropping breaks Europe polygon. Need to fix it
  plot.symbol(db.c1,
              nameSize = "AdjustedBurrowDensity",
              nameColor="AdjustedBurrowDensity",
              flagLegend = T,
              legendNameColor="Adjusted Burrow Density",
              legendNameSize="Adjusted Burrow Density") +
  plot.decoration(title=paste0(mt, " (stns inside polygon)"), xlab="Longitude", ylab="Latitude") +
  plot.polygon(pol.FU17_m, fill=NA)

```



##Summary statistics
<a href="#top">Back to top</a>

Getting summary statistics for inside the polygon. Mean, variance, histogramme of data inside polygon.
 
```{r summary_stats, echo=TRUE}

# Mean, variance, histogram of data inside polygon.
# Two methods:

# From gstlearn (but numbers are rounded):
dbfmt = DbStringFormat_createFromFlags(flag_stats=TRUE, names=c("AdjustedBurrowDensity"))
db.c1$display(dbfmt)

plot.init() +
  plot.hist(db.c1, name="AdjustedBurrowDensity", bins=13, fill="blue")

# Manually:
zm<-mean(db.c1[,c("AdjustedBurrowDensity")][db.c1[,c("Polygon")]==1],na.rm=T) #average burrow density inside polygon - burrows per m²
zv<-var(db.c1[,c("AdjustedBurrowDensity")][db.c1[,c("Polygon")]==1],na.rm=T)*(sum(db.c1[,c("Polygon")],na.rm=T)-1)/sum(db.c1[,c("Polygon")],na.rm=T) #spread of the values around the mean
cat("mean: ",zm,"    var: ",zv,"   cv: ",sqrt(zv)/zm,"\n") #relative variability

hist(db.c1[,c("AdjustedBurrowDensity")][db.c1[,c("Polygon")]==1],nclass=20,xlab="burrow density n/m^2",main=mt) #frequency distribution of burrow density values

```


## Variograms
<a href="#top">Back to top</a>
Setting up the experimental variogram and plotting the points. Fitting an experimental variogram to the pairs.
 
```{r fitting_vario, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Fitted variogram."}


# Get suggestions for nlag and dlag parameters
sug <- suggest_lag_params(db.c1[,c("x", "y")], min_pairs = 50)
sug$nlag # nlag2024 = 8;        nlag2025 = 8

sug$dlag # nlag2024 = 6071.515; dlag2025 = 6299.665

# Compute the experimental variogram:
varioParamOmni <- VarioParam_createOmniDirection(nlag = sug$nlag, dlag = sug$dlag)
db.c1$setLocator("AdjustedBurrowDensity",ELoc_Z())
varioexp = Vario(varioParamOmni)
err = varioexp$compute(db.c1) # 0 means "no errors"

varioexp

# plot.init() + plot.varmod(varioexp)
plot.init() + plot.varmod(varioexp,drawPsize=TRUE) +
  plot.decoration(xlab="Distance (m)")

# We then the fit a model fitmod (automatic model fitting)
fitmod = Model()
# types = ECov_fromKeys(c("NUGGET","EXPONENTIAL","GAUSSIAN")) # If we want Model Fitting with pre-defined basic structures
types = ECov_fromKeys(c("SPHERICAL")) # If we want Model Fitting with pre-defined basic structures
err = fitmod$fit(varioexp,types=types)
# err = fitmod$fit(varioexp)
# Plot both experimental variogram and fitted model
plot.init() + plot.varmod(varioexp, fitmod) +
  plot.decoration(xlab="Distance (m)")

fitmod


# Variogram Maps ----
var.vmap = db_vmap(db.c1)
p1 = plot.init() + plot.raster(var.vmap, flagLegend=TRUE, legendName="Adjusted\nBurrow\nDensity\nVar")
p2 = plot.init() + plot.raster(var.vmap, name="VMAP.AdjustedBurrowDensity.Nb", flagLegend=TRUE, legendName="# pairs")
ggarrange(p1,p2,nrow=1,ncol=2)
```


## Creating the grid.
<a href="#top">Back to top</a>

This step involves making a grid of points within the domain area. This grid is used for the modeled surface. A grid of 100X100 points was chosen because it was similar to the previous methodology in SURFER. The grid is plotted along with the domain boundary and bubbles of density.

```{r making_grid, echo=TRUE, message=TRUE, fig.cap="Gridded data plot."}



# Grid for historical ggins in decimal degrees
gnx=99;gny=99 # to match the 100x100 from RGeostats and be able to plot historical data together
gx0=min(coords[,1]); gx1=max(coords[,1])
gy0=min(coords[,2]); gy1=max(coords[,2])
gdx=(gx1-gx0)/gnx; gdy=(gy1-gy0)/gny

grid_ggin = DbGrid_create(x0=c(gx0, gy0),
                     dx=c(gdx, gdy),
                     nx=c(100, 100))

# Grid for kriging in metres
gnx=99;gny=99
gx0=min(prep$polygon_xy[,1]); gx1=max(prep$polygon_xy[,1])
gy0=min(prep$polygon_xy[,2]); gy1=max(prep$polygon_xy[,2])
gdx=(gx1-gx0)/gnx; gdy=(gy1-gy0)/gny

grid_m = DbGrid_create(x0=c(gx0, gy0),
                     dx=c(gdx, gdy),
                     nx=c(100, 100))

# select points inside polygon
db_polygon(grid_ggin, pol.FU17) # degrees

db_polygon(grid_m, pol.FU17_m) # metres

# Print summary with info about the extent of the grid
dbfmt = DbStringFormat_createFromFlags(flag_extend=TRUE) 
grid_m$display(dbfmt)

# Now only "active samples" inside the polygon will be plotted
plot.init() + # Cropping breaks Europe polygon. Need to fix it
  plot.raster(grid_ggin) +
  plot.symbol(data.db,
              nameSize = "AdjustedBurrowDensity",
              nameColor="AdjustedBurrowDensity",
              flagLegend = T,
              legendNameColor="Adjusted Burrow Density",
              legendNameSize="Adjusted Burrow Density") +
  plot.decoration(title=paste0(mt, " GRID and stns inside polygon"), xlab="Longitude", ylab="Latitude") +
  plot.polygon(pol.FU17, fill=NA)

# Now only "active samples" inside the polygon will be plotted
plot.init() + # Cropping breaks Europe polygon. Need to fix it
  plot.raster(grid_m) +
  plot.symbol(db.c1,
              nameSize = "AdjustedBurrowDensity",
              nameColor="AdjustedBurrowDensity",
              flagLegend = T,
              legendNameColor="Adjusted Burrow Density",
              legendNameSize="Adjusted Burrow Density") +
  plot.decoration(title=paste0(mt, " GRID and stns inside polygon"), xlab="Longitude", ylab="Latitude") +
  plot.polygon(pol.FU17_m, fill=NA)
```

## Simple Kriging
<a href="#top">Back to top</a>

Here we carry out the kriging using the fitted variogram.
Neighbourhood weighting is not needed given the properties of this data set (i.e. <50 observations which are fairly homogeneous and strongly auto-correlated).

```{r krige_model, echo=TRUE, message=TRUE, eval=TRUE}
# We then create a “neighborhood” object corresponding to the specification of a unique neighborhood.
uniqueNeigh = NeighUnique()

# SIMPLE KRIGING ----
# Just for testing. This kriging is wrong as it assumes a mean = 0

# We now call the kriging function to perform the kriging prediction.
# We use the model fitmod that we previously fitted on our data,
# require to compute the kriging predictor and its standard-deviation (but not its variance),
# and change the prefix of the newly created variables to “SK”.
err = kriging(dbin=db.c1, dbout=grid_m, model=fitmod, 
              neigh=uniqueNeigh,
              flag_est=TRUE, flag_std=TRUE, flag_varz=FALSE,
              namconv=NamingConvention("SK"))

# We see that the kriging predictor and its standard deviation have been added to the grid data base.
grid_m

# Plot the kriging prediction over the grid using the plot.raster function and the data points.
p = plot.init(asp=1)
p = p + plot.raster(grid_m,
                    flagLegend = TRUE, palette="Spectral",legendName="Kriged\nAdjusted\nBurrow\nDensity") 
p = p + plot.symbol(db.c1,
                    nameSize = "AdjustedBurrowDensity",
                    flagLegend = T,
                    legendNameSize="Adjusted\nBurrow\nDensity")
p = p + plot.decoration(title="SIMPLE KRIGING over whole Grid")
plot.end(p)

# By default, the plotting function plots the variable with locator z1,
# which in our case corresponds to the kriging predictor (as the kriging function automatically assigns the locator z1 to it).
# To plot another variable, we can simply specify their name.
# For instance, we can plot the kriging standard deviation using the following code.

p = plot.init(asp=1)
p = p + plot.raster(grid_m,name="SK.AdjustedBurrowDensity.stdev",
                    flagLegend = TRUE, palette="Spectral",legendName="sd")
p = p + plot.symbol(db.c1,flagCst = T,pch=18,cex=1.5)
p = p + plot.decoration(title="SIMPLE KRIGING std-dev over whole Grid")
plot.end(p)
```
 
### Ordinary Kriging
<a href="#top">Back to top</a>

his kriging assumes an unknown constant.

```{r krige_res1, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Kriged Density Adjusted.estimated."}

# Considering the model fitmod previously fitted on the data, we can clone it (using the clone method), and add a constant drift as follows.
fitmodOK = fitmod$clone()
err = fitmodOK$addDrift(DriftM())

# Then, ordinary kriging is performed using the same command as before, but with the newly created model.
err = kriging(dbin=db.c1, dbout=grid_m, model=fitmodOK, 
              neigh=uniqueNeigh,
              flag_est=TRUE, flag_std=TRUE, flag_varz=FALSE,
              namconv=NamingConvention("OK"))
# Finally, we plot the new kriging prediction over the grid and the data points.
p = plot.init(asp=1)
p = p + plot.raster(grid_m,
                    flagLegend = TRUE, palette="Spectral",legendName="Kriged\nAdjusted\nBurrow\nDensity") 
p = p + plot.symbol(db.c1,
                    nameSize = "AdjustedBurrowDensity",
                    flagLegend = T,
                    legendNameSize="Adjusted\nBurrow\nDensity")
p = p + plot.decoration(title="ORDINARY KRIGING over whole Grid")
plot.end(p)

# And the sd
p = plot.init(asp=1)
p = p + plot.raster(grid_m,name="OK.AdjustedBurrowDensity.stdev",
                    flagLegend = TRUE, palette="Spectral",legendName="sd")
p = p + plot.symbol(db.c1,flagCst = T,pch=18,cex=1.5,
                    legendNameSize="Adjusted Burrow Density")
p = p + plot.decoration(title="ORDINARY KRIGING std-dev over whole Grid")
plot.end(p)
```  

 
### Compare SK, OK plots
<a href="#top">Back to top</a>


```{r krige_res2, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Kriged Density Adjusted.standard deviation."} 

# Let us compare the results from the simple and ordinary kriging predictors.
# To do so, we create a correlation plot between the two predictors.
p = plot.init()
p = p + plot.correlation(grid_m,namex="OK.AdjustedBurrowDensity.estim",namey="SK.AdjustedBurrowDensity.estim", 
                         flagBiss=TRUE, flagSameAxes=TRUE, bins=100)
p = p + plot.decoration(title="Estimation SIMPLE vs. ORDINARY", 
                        xlab="Ordinary Kriging", ylab="Simple Kriging")
plot.end(p)

# We also compare the kriging standard-deviations obtained in both cases.
p = plot.init()
p = p + plot.correlation(grid_m,namex="OK.AdjustedBurrowDensity.stdev",namey="SK.AdjustedBurrowDensity.stdev", 
                         flagBiss=TRUE, flagSameAxes=TRUE, bins=100)
p = p + plot.decoration(title="St. dev. SIMPLE vs. ORDINARY", 
                        xlab="Ordinary Kriging", ylab="Simple Kriging")
plot.end(p)

# And we compare the numbers
## Global estimation by arithmetic average:
global.ar <- global_arithmetic(db.c1, grid_m, fitmod, ivar0 = 0, verbose = 1) # Global estimation by arithmetic average 

## Global estimation kriging:
global.ma_SK <- global_kriging(db.c1, grid_m, fitmod, ivar0 = 0, verbose=1) # SIMPLE kriging

global.ma_OK <- global_kriging(db.c1, grid_m, fitmodOK, ivar0 = 0, verbose=1) # ORDINARY kriging

# Arithmetic estimates
cat("arith.mean: ",round(global.ar$zest,7)," CV.geo: ",round(global.ar$cvgeo,8)," SSE: ",sse<-round(global.ar$cvgeo*global.ar$zest,8),"\n")

# Simple Kriging estimates (just for testing)
cat("SK.mean: ",round(global.ma_SK$zest,7)," CV.geo: ",round(global.ma_SK$cvgeo,8),"\n")

# Ordinary kriging estimates (very close to the arithmetic estimates because we have a regular grid and we have an almost-flat variogram)
cat("OK.mean: ",round(global.ma_OK$zest,7)," CV.geo: ",round(global.ma_OK$cvgeo,8),"\n")
```

 

## ggin contour data
<a href="#top">Back to top</a>

We want to save ggin, for this we run the kriging again in an empty grid. So we only have the ordinary kriging outputed. And we want it with decimal degrees to match historical format.

```{r krige_summ, echo=TRUE, message=TRUE, eval=TRUE}

err = kriging(dbin=data.db, dbout=grid_ggin, model=fitmodOK, 
              neigh=uniqueNeigh,
              flag_est=TRUE, flag_std=TRUE, flag_varz=FALSE)

ggin <- as.data.frame(grid_ggin[])
ggin$Polygon <- ggin$Polygon == 1 # Convert to logical to match historical format
ggin$Kriging.AdjustedBurrowDensity.estim[is.na(ggin$Kriging.AdjustedBurrowDensity.estim)] <- 0
ggin$Kriging.AdjustedBurrowDensity.stdev[is.na(ggin$Kriging.AdjustedBurrowDensity.stdev)] <- 0

#if (save.tables == T) {
  #write.csv(ggin, file= paste0("ggins historic/ggin", surv.yr, ".csv"))
#}
```



### Survey abundance estimate in numbers (millions)
<a href="#top">Back to top</a>

```{r Survey_abundance, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Cross validation plot."}
# Survey abundance estimate in numbers (millions) 
abun <- global.ma_OK$zest*pol.FU17_m$getSurface()/1000000

# read in summary file from surfer calculation
k.sum <- read.csv("boot/data/UWTV/AranGrounds.Summary.ADG.2024.csv")

#k.sum <- k.sum[,!names(k.sum) == "X"]

k.sum <- rbind(k.sum, data.frame(Year=mean(nep$Year), Ground ="Aran", mean= zm,  N= sum(sapply(0:(db.c1$getNSample()-1), function(i) db.c1$isActive(i))),  
                   sd = zv/zv^.05, se= sse, ciMult=NA, ci= abun*global.ma_OK$cvgeo*1.96, 
                   area= pol.FU17_m$getSurface()/1000000, abund = abun, 
                   upper= abun+abun*global.ma_OK$cvgeo*1.96, 
                  lower= abun-abun*global.ma_OK$cvgeo*1.96, 
                   CViid= zv/zm, meanGeo=  global.ma_OK$zest, CVgeo= global.ma_OK$cvgeo, method ="gstlearn"))

if (save.tables == T) {
  write.csv(k.sum, "model/model_02_UWTV_Kriging_Method_Aran/fu17.uwtv.summary.statistics.adg.csv", row.names = F)
}

knitr::kable(k.sum[,1:8] )
knitr::kable(k.sum[,c(1, 9:15)])

```



## Cross-validation
<a href="#top">Back to top</a>
```{r cross_val, echo=TRUE, message=TRUE, eval=TRUE}

err = xvalid(db=db.c1, model=fitmodOK, neigh=uniqueNeigh, 
             flag_xvalid_est=1, flag_xvalid_std=1,  
             namconv=NamingConvention_create("Xvalid", flag_locator = FALSE) # We specify, through the nameconv that we do not wish to modify the current locators in the data base (otherwise, the locator z1 is “moved” to the variable containing the cross-validation error).
            )
# Histogram of cross-validation errors
p = plot.init()
p = p + plot.hist(db.c1,name="*esterr*",bins=30,fill="blue")
p = p + plot.decoration(xlab="Estimation Errors", title="Cross-Validation")
plot.end(p)

# Histogram of standardized errors
p = plot.init()
p = p + plot.hist(db.c1,name="*stderr*",bins=30,fill="blue")
p = p + plot.decoration(xlab="Standardized Errors", title="Cross-Validation")
plot.end(p)

# Finally, we compute a few statistics about these errors.
print(c("Mean cross-validation error:",round(mean(db.c1$getColumn("*esterr*"),na.rm=TRUE),5)))

print(c("Mean squared cross-validation error:",round(mean(db.c1$getColumn("*esterr*")^2,na.rm=TRUE),5)))

print(c("Mean standardized error:",round(mean(db.c1$getColumn("*stderr*")^2,na.rm=TRUE),5)))

# Plot the absolute value of the cross-validation errors at each point on top of the grid map
p = plot.init(asp=1)
p = p + plot.raster(grid_m,"OK.AdjustedBurrowDensity.estim")
p = p + plot.symbol(db.c1,nameSize="*esterr",flagAbsSize = TRUE)
p = p + plot.decoration(title="Cross-Validation scores")
plot.end(p)
```

### Summary results (with historical data)
Finally a summary of the results over time-series.
```{r final_res_hist, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Number of UWTV survey stations."}

  ggplot(k.sum, aes(x=Year,y=N)) + geom_line(linewidth = 1) +  geom_point() +        
    theme_bw() +
          scale_x_continuous(name="\nYear",
                             breaks = seq(min(k.sum$Year), max(k.sum$Year), 2)) +
          scale_y_continuous(name = "Number of Stations \n",
                             breaks = seq(0, max(k.sum$N)+10, 10),
                             limits = c(0, max(k.sum$N)+10)) +
          theme(panel.grid=element_blank(), legend.position = "bottom")  +
          theme(legend.title=element_blank())  

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_Number_UWTV_Stations.png")
}
```


### Abundance estimate (millions individuals)
WKFMSY Btrigger estimated in 2016.

```{r Abun_estimate, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Abundance estimate (millions of individuals)."}

ggplot(k.sum, aes(x=Year, y= abund)) +
          theme_bw() +
          geom_errorbar(aes(ymax=upper, ymin=lower, width=0.25)) +
          geom_line(size = 1) +
          geom_point() +
          theme(panel.grid = element_blank()) +
          scale_x_continuous(name="\nYear",
                             breaks = seq(min(k.sum$Year), max(k.sum$Year), 2)) +
          scale_y_continuous(name = "Abundance (millions)\n",
                             breaks = seq(0, max(k.sum$upper)+100, 250),
                             limits = c(0, max(k.sum$upper)+100)) + 
          geom_hline(aes(yintercept=540),colour="#990000",linetype="dashed",size = 0.9) 

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_Abundance_estimates.png")
}


```

  
### Uncertainty estimate

```{r Uncertainty_estimate, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Uncertainty estimate. Dashed line is 20% limit."}


ggplot(k.sum, aes(x=Year, y= CVgeo)) +
          theme_bw() +
          geom_line(size = 1) +
          geom_point() +
          theme_bw() +
          geom_hline(aes(yintercept=0.20),colour="black",linetype="dashed",size = 0.5) +
          scale_x_continuous(name="\nYear",
                             breaks = seq(min(k.sum$Year), max(k.sum$Year), 5)) +
          scale_y_continuous(name = "CV Geo",
                             breaks = seq(0, max(k.sum$CVgeo)+0.15, 0.01),
                             limits = c(0, max(k.sum$CVgeo)+0.15))  +
          theme(panel.grid=element_blank(), legend.position = "bottom")  +
          theme(legend.title=element_blank())  



if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_uncertainty_estimate.png")
}


with(k.sum, plot(Year, CViid, type="l", ylim=c(0,0.21), ylab="CV", main="CV estimates"))
with(k.sum, lines(Year, CVgeo, type="l", col="red"))
abline(h=0.2, lty=2, col="green")
legend("topleft",c("CVgeo", "CViid", "WGNEPS Limit"), col =c(2,1, "green"), lty = c(1,1,2) )


```


### Mean Density estimate (burrow/m2)

```{r Mean_Den, echo=TRUE, message=TRUE, eval=TRUE, fig.cap="Mean density estimate (burrow/m2)."}

ggplot(k.sum, aes(x=Year, y= mean)) +
          theme_bw() +
          geom_line(size = 1) +
          geom_point() +
          theme_bw() +
          scale_x_continuous(name="\nYear",
                             breaks = seq(min(k.sum$Year), max(k.sum$Year), 2)) +
          scale_y_continuous(name = "Mean Density (burrow/m-2)",
                             breaks = seq(0, max(k.sum$mean)+0.3, 0.1),
                             limits = c(0, max(k.sum$mean)+0.3))  +
          theme(panel.grid=element_blank(), legend.position = "bottom")  +
          theme(legend.title=element_blank())  

if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_meandensity.png")
}
```


### Krigged contour plots over time.
<a href="#top">Back to top</a>

GGins are compiled from previous files.

```{r contour, echo=TRUE, message=TRUE, eval=TRUE, fig.height=11, fig.width=8, fig.cap="Kriged contour and density bubble plot."}
ggin <- read.csv("model/UWTV/ggins.compiled.Aran.contourplot.csv")

shapefile_path_FG <- "model/shp/nep.17.aran.shp"
shapefile_path_IRE <- "model/shp/eire.shp"

file.exists(shapefile_path_FG)
FG <- st_read(shapefile_path_FG)
print(FG)

##data checks for station spacing
ggin$Density[is.na(ggin$Density)==T]
ggin$Density[ggin$Density<0]<-0.0
range(ggin$Density)
range(ggin$longitude)
range(ggin$latitude)

#station spacing
x <- sort(unique(ggin$longitude))
y <- sort(unique(ggin$latitude))
summary(head(x, -1) - tail(x, -1))
summary(head(y, -1) - tail(y, -1))


latlimits <- c(52.75, 53.25)
longlimits <- c(-10.5, -9.5)

 p <- 
   ggplot(data = FG) +
   geom_sf(fill = "lightgrey", color = "darkgrey", size = 0.5) +  # Customize fill and border color
   geom_tile(data = subset(ggin, Polygon == TRUE), 
            aes(x = round(longitude, 2), 
                y = round(latitude, 2), 
                fill = Density)) +
    scale_fill_gradientn(colours = brewer.pal(9, "YlOrRd"), guide = "legend") +
   theme_bw() +
   coord_sf(xlim = longlimits, ylim = latlimits) +  # Use coord_sf for spatial data
   scale_x_continuous(labels = function(x) paste0(abs(x), "°")) + # Remove "W", keep degree symbol
   scale_y_continuous(labels = function(y) paste0(abs(y), "°")) +
   labs(y = "Latitude", x = "Longitude") +
   facet_wrap(~year, nrow = 5)  # Facet by year
 

surv <- nep.all
names(surv)[2] <- "year"
names(surv)[12] <- "mid_lon"
names(surv)[13] <- "mid_lat"
names(surv)[21] <- "Adjusted_Density"

b <- geom_point(data=surv, aes(x=mid_lon, y=mid_lat, size=Adjusted_Density), shape =1)

f <- p + b



f + theme(axis.title.x=element_text(size=12, margin = margin(t = 15)),
          axis.text=element_text(size=10),
          axis.title.y=element_text(size=12, margin = margin(r = 20)), #Latitude
          strip.text.x=element_text(size=10),
          legend.title = element_text(size=10), #"Adjusted Burrow Density"
          legend.text=element_text(size= 6), #labels inside the legend (the tick labels for colour/size).
          legend.key.size = unit(1, "cm")) #(the little coloured tiles/squares).


if (save.plots == T) {
ggsave("model/model_02_UWTV_Kriging_Method_Aran/FU17_contour_plot.png")
}

```
<a href="#top">Back to top</a>

## Session
<a href="#top">Back to top</a>
```{r info , echo=TRUE, warning=FALSE, fig.height=8, fig.width=8}
session_info()

```